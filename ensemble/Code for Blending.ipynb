{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 들어가며\n",
    "\n",
    "  Kaggle 대회들의 상위 솔루션들을 살펴보면 여러 모델을 만든 뒤에 각 모델의 결과를 조합하여 하나의 결과로 만드는 방식으로 성능을 올리는 모습을 자주 볼 수 있습니다. 본 노트북은 [Mechanisms of Actions Prediction](https://www.kaggle.com/c/lish-moa/overview)이라는 대회에서 [4등을 한 팀의 솔루션](https://www.kaggle.com/kento1993/nn-svm-tabnet-xgb-with-pca-cnn-stacking-without-pp)을 리뷰하는 과정에서 알게된 **Blending**이라는 방법을 살펴봅니다.\n",
    "  \n",
    "  이 노트북을 보는 분들이 저와 같은 의문을 가지고 그 답을 찾기위한 검색을 하는데 시간을 쓰지 않으시기를 바라는 마음에서 요약을 하기보다는 공부를 해나간 순서대로 전부 기록하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MoA 및 Blending 간단 소개\n",
    "\n",
    "  MoA의 목표는 Multi-label classification입니다. 따라서 모든 클래스에 대한 binary classification을 진행하게 됩니다. 각 클래스에 대한 모델의 아웃풋은 0과 1 사이의 실수가 됩니다.\n",
    "  \n",
    "  이와 같은 태스크 아래에서 여러 모델의 아웃풋을 조합하는 방법으로 가장 먼저 생각할 수 있는 것은 단순 평균입니다. 여기서 조금 더 나아가서 각 모델의 아웃풋에 가중치를 부여해서 가중 평균을 구할 수도 있을 것입니다. 이러한 관점에서 볼 때 Blending은 **어떻게 좋은 가중치를 찾을 것인가?**와 관련되어 있습니다.\n",
    "  \n",
    "  Blending에 대해 조금 더 자세히 들여다보고 싶으신 분은 [링크](https://mlwave.com/kaggle-ensembling-guide/)를 참고하시길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  예시를 위해 True Label과 OOF Predictions을 '의도적으로' 만들겠습니다.\n",
    "  \n",
    "  * sample은 총 1000개, class는 총 200개로, true label은 50%의 확률로 1 또는 0입니다.\n",
    "  * 모델은 총 4개가 있으며, \n",
    "    1. 모델1은 모든 class를 0으로\n",
    "    2. 모델2는 0~149번째 class는 1, 나머지는 0으로\n",
    "    3. 모델3은 50~199번째 class는 1, 나머지는 0으로\n",
    "    4. 모델4는 50~149번째 class는 1, 나머지는 0으로\n",
    "  예측하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some labels and 4 prediction sets.\n",
    "y = (np.random.rand(1000, 200) > 0.5).astype(int)\n",
    "pred1 = np.zeros((1000, 200))\n",
    "pred2 = np.zeros((1000, 200))\n",
    "pred2[:, :150] = 1\n",
    "pred3 = np.zeros((1000, 200))\n",
    "pred3[:, 50:] = 1\n",
    "pred4 = np.zeros((1000, 200))\n",
    "pred4[:, 50:150] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([pred1, pred2, pred3, pred4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Blending을 하는 코드를 살펴보기 전에 어떤 예측이 위의 True Label에 대해 손실 함수를 최소화 하는지 잠깐 생각해보겠습니다.\n",
    "  \n",
    "  각 class에 대한 binary classification을 하고 있기 때문에 손실 함수는 각 class에 대한 binary cross-entropy가 될 것입니다. 여기서 True Label은 50%의 확률로 1 또는 0이기 때문에 **모든 예측이 0.5가 된다면 손실 함수가 최소화** 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MoA 4등 팀의 솔루션 중 Blending을 하는 부분의 코드는 아래와 같습니다.\n",
    "\n",
    "```python\n",
    "def get_score(weights, train_idx, oofs, labels):\n",
    "        blend = np.zeros_like(oofs[0][train_idx, :])\n",
    "        \n",
    "        for oof, weight in zip(oofs[:-1], weights):\n",
    "            blend += weight * oof[train_idx, :]\n",
    "            \n",
    "        blend += (1 - np.sum(weights)) * oofs[-1][train_idx, :]\n",
    "        return logloss_for_multilabel(labels[train_idx, :], blend)\n",
    "\n",
    "def get_best_weights(oofs, labels):\n",
    "    weight_list = []\n",
    "    weights = np.array([1/len(oofs) for x in range(len(oofs) - 1)])\n",
    "    \n",
    "    for n_splits in tqdm([5, 6]):\n",
    "        for i in range(2):\n",
    "            kf = KFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(X=oofs[0])):\n",
    "                res = minimize(get_score, weights, args=(train_idx, oofs, labels), method=\"Nelder-Mead\", tol=1e-6)\n",
    "                logger.info(f\"i: {i} fold: {fold} res.x: {res.x}\")\n",
    "                weight_list.append(res.x)\n",
    "                \n",
    "    mean_weight = np.mean(weight_list, axis=0)\n",
    "    print(f\"optimized weight: {mean_weight}\")\n",
    "    return mean_weight\n",
    "\n",
    "best_weights = get_best_weights(stage3_oofs, train_features_df[stage_1_2_target_cols].values)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시를 간단하게 만들기 위해 `n_splits`와 `KFold`를 제거 하겠습니다. 또한 손실 함수가 필요하기 때문에 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_numpy(y_pred, y_true):\n",
    "    y_true_ravel = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = np.where(y_true_ravel == 1, - np.log(y_pred), - np.log(1 - y_pred))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `log_loss_numpy`는 multi-label classification의 손실 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(weights, oofs, labels):\n",
    "        blend = np.zeros_like(oofs[0])\n",
    "\n",
    "        for oof, weight in zip(oofs[:-1], weights):\n",
    "            blend += weight * oof\n",
    "\n",
    "        blend += (1 - np.sum(weights)) * oofs[-1]\n",
    "        loss = log_loss_numpy(blend, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_score`는 `oofs`와 `weights`를 가중합 한 뒤에 그 결과를 True label과 함께 손실 함수에 넣어 계산합니다.\n",
    "<br>\n",
    "\n",
    "* 가중합을 계산할 때 마지막 oof, `oofs[-1]`의 가중치는 `1 - np.sum(weights)`가 됩니다.\n",
    "<br>\n",
    "\n",
    "* 그에 따라 `weights의 길이`는 `oofs의 길이 - 1`이 됩니다. (`len(weights) == len(oofs)-1`)\n",
    "<br>\n",
    "\n",
    "* `get_score`는 `x0`와 함께 밑에 정의 될 `minimize` 함수의 인자로 주어지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_weights(oofs, labels):\n",
    "    x0 = np.array([1/len(oofs) for x in range(len(oofs) - 1)])\n",
    "    res = minimize(get_score, x0, args=(oofs, labels, ), method=\"Nelder-Mead\", tol=1e-10)\n",
    "    print(res)\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_best_weights`는 OOF predictions의 리스트인 `oofs` 인자와 True label인 `labels` 인자를 받아서 최적의 가중치를 구하는 함수입니다. \n",
    "<br>\n",
    "\n",
    "* scipy.optimize에 있는 `minimize`라는 함수를 이용하고 있으며, Nelder-Mead라는 방법을 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minimize`에 대한 자세한 내용은 [링크](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)를 참고하시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nelder-Mead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Nelder-Mead는 휴리스틱한 최적화 방법으로 gradient가 필요하지 않습니다. 그리고 **constraint를 사용할 수 없습니다**.\n",
    "  \n",
    "references:\n",
    "1. https://sudonull.com/post/69185-Nelder-Mead-optimization-method-Python-implementation-example\n",
    "2. https://codesachin.wordpress.com/2016/01/16/nelder-mead-optimization/\n",
    "3. https://people.duke.edu/~ccc14/sta-663/BlackBoxOptimization.html\n",
    "4. https://github.com/fchollet/nelder-mead/blob/master/nelder_mead.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nelder-Mead는 constraint를 사용할 수 없는데, 가중 평균의 가중치들은 constraint를 갖고 있습니다.\n",
    "\n",
    "1. 모든 가중치들은 0과 1 사이의 실수이며,\n",
    "2. 모든 가중치들의 합은 1이 되어야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MoA 4등 솔루션은 간접적으로 위와 같은 constraint를 적용하려고 시도 하였습니다.\n",
    "\n",
    "```python\n",
    "def get_score(weights, oofs, labels):\n",
    "        blend = np.zeros_like(oofs[0])\n",
    "\n",
    "        for oof, weight in zip(oofs[:-1], weights):\n",
    "            blend += weight * oof\n",
    "\n",
    "        blend += (1 - np.sum(weights)) * oofs[-1]\n",
    "        return log_loss_numpy(labels, blend)\n",
    "```\n",
    "에서 `weights`는 `전체 모델의 개수 - 1`개이며, 마지막 가중치는 `(1 - np.sum(weights))`가 되는 형태로 **`constraint 2`** 를 해결했습니다. 이것이 위에서 `get_best_weights` 함수가 가중치를 2개만 리턴한 이유입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇지만 이 방법은 **`constraint 1`** 을 해결하지 못했습니다. MoA 4등 솔루션은 `get_best_weights`가 리턴한 각 가중치들이 0과 1 사이의 실수이고 그 합이 1보다 작았지만, 실제로 위와 같이 하면 가중치가 음수가 나오거나 합이 1을 넘어갈 수 있습니다.\n",
    "\n",
    "references:\n",
    "1. https://www.kaggle.com/c/lish-moa/discussion/186539#1039438\n",
    "2. http://www.acme.byu.edu/wp-content/uploads/2016/12/Vol2B-ScipyOptimize-20171.pdf pp.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[0.4993    , 0.49852   , 0.50032001],\n",
      "       [0.4993    , 0.49852   , 0.50032001],\n",
      "       [0.4993    , 0.49852   , 0.50032001],\n",
      "       [0.4993    , 0.49852   , 0.50032001]]), array([0.69314554, 0.69314554, 0.69314554, 0.69314554]))\n",
      "           fun: 0.6931455441581822\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 253\n",
      "           nit: 126\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.4993    , 0.49852   , 0.50032001])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4993    , 0.49852   , 0.50032001])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_weights(preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 예시의 결과는 `[0.4993, 0.49852, 0.50032]`으로 그 합이 1이 넘어가며 모델4의 가중치가 음수가 나오게 됨을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constrained Optimization; SLSQP\n",
    "\n",
    "  제대로 된 가중치를 찾기 위해서는 Constrained optimization을 하면 된다고 합니다.\n",
    "  \n",
    "references:\n",
    "1. https://www.kaggle.com/tolgadincer/blending-multilabeled-models-with-scipy\n",
    "2. https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_numpy_metric(weights, oofs, labels):\n",
    "    oof_blend = np.tensordot(weights, oofs, axes = ((0), (0)))\n",
    "    return log_loss_numpy(oof_blend, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nelder-Mead 예시에서의 `get_score`와 같은 역할을 하는 함수힙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_weights_constrained(oofs, labels):\n",
    "    tol = 1e-10\n",
    "    init_guess = [1 / len(oofs)] * len(oofs)\n",
    "    bnds = [(0, 1) for _ in range(len(oofs))]\n",
    "    cons = {'type': 'eq', \n",
    "            'fun': lambda x: np.sum(x) - 1, \n",
    "            'jac': lambda x: [1] * len(x)}\n",
    "\n",
    "    res_scipy = minimize(fun = func_numpy_metric, \n",
    "                         x0 = init_guess,\n",
    "                         args=(oofs, labels),\n",
    "                         method = 'SLSQP',\n",
    "                         bounds = bnds, \n",
    "                         constraints = cons, \n",
    "                         tol = tol)\n",
    "\n",
    "    print(res_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nelder-Mead 방법 대신 SLSQP 라는 방법을 사용하고 있습니다.\n",
    "<br>\n",
    "\n",
    "* initial guess의 길이가 oofs의 길이와 같습니다.\n",
    "<br>\n",
    "\n",
    "* constraint를 설명하는 `bnds`와 `cons`가 추가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLSQP를 이용한 minimize 사용에 대한 자세한 내용은 [링크](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#sequential-least-squares-programming-slsqp-algorithm-method-slsqp)를 참고해주시길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 0.746401813877979\n",
      "     jac: array([ 0.00000000e+00, -8.51601362e-06, -8.30739737e-06,  2.29398616e-01])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 35\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.39013821, 0.30426809, 0.3055937 , 0.        ])\n"
     ]
    }
   ],
   "source": [
    "get_best_weights_constrained(preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시의 결과가 대략 `[0.390, 0.304, 0.306, 0]`으로 그 합이 1이 되며, 모든 가중치가 0과 1사이의 실수임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SLSQP`는 gradient가 필요한 방법입니다. `minimize`에 `jac`인자를 넘겨주지 않는 경우에는 2-point numerical gradient를 이용해서 gradient를 계산하게 됩니다.\n",
    "\n",
    "references:\n",
    "1. https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "2. https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#sequential-least-squares-programming-slsqp-algorithm-method-slsqp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jac`을 정의해서 optimize 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_func(weights, oofs, labels):\n",
    "    oof_clip = np.clip(oofs, 1e-15, 1 - 1e-15)\n",
    "    gradients = np.zeros(oofs.shape[0])\n",
    "    for i in range(oofs.shape[0]):\n",
    "        a, b, c = labels, oof_clip[i], np.zeros((oofs.shape[1], oofs.shape[2]))\n",
    "        for j in range(oofs.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_weights_constrained_jac(oofs, labels):\n",
    "    tol = 1e-10\n",
    "    init_guess = [1 / preds.shape[0]] * preds.shape[0]\n",
    "    bnds = [(0, 1) for _ in range(preds.shape[0])]\n",
    "    cons = {'type': 'eq', \n",
    "            'fun': lambda x: np.sum(x) - 1, \n",
    "            'jac': lambda x: [1] * len(x)}\n",
    "\n",
    "    res_scipy = minimize(fun = func_numpy_metric, \n",
    "                         x0 = init_guess,\n",
    "                         args=(oofs, labels),\n",
    "                         method = 'SLSQP',\n",
    "                         jac = grad_func,\n",
    "                         bounds = bnds, \n",
    "                         constraints = cons, \n",
    "                         tol = tol)\n",
    "\n",
    "    print('Optimised Weights:', res_scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised Weights:      fun: 0.7464018138778526\n",
      "     jac: array([-2.29415462e-16, -8.52403602e-06, -8.31271598e-06,  2.29398626e-01])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 7\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.90138194e-01, 3.04268099e-01, 3.05593707e-01, 5.33986511e-17])\n"
     ]
    }
   ],
   "source": [
    "get_best_weights_constrained_jac(preds, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
